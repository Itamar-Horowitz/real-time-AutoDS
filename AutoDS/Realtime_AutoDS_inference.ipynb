{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Itamar-Horowitz/real-time-AutoDS/blob/main/AutoDS/Realtime_AutoDS_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpCtYevLHfl4"
      },
      "source": [
        "# **AutoDS**\n",
        "\n",
        "---\n",
        "\n",
        "<font size = 4> Deep-STORM is a neural network capable of image reconstruction from high-density single-molecule localization microscopy (SMLM), first published in 2018 by [Nehme *et al.* in Optica](https://www.osapublishing.org/optica/abstract.cfm?uri=optica-5-4-458). The architecture used here is a U-Net based network without skip connections. This network allows image reconstruction of 2D super-resolution images, in a supervised training manner. The network is trained using simulated high-density SMLM data for which the ground-truth is available. These simulations are obtained from random distribution of single molecules in a field-of-view and therefore do not imprint structural priors during training. The network output a super-resolution image with increased pixel density (typically upsampling factor of 8 in each dimension).\n",
        "\n",
        "<font size = 4> AutoDS is an extension of Deep-STORM automating the reconstruction process and aleviating the need in human intervension. This is done by automatic detection of the experimental condition in the analyzed videos and automatic selection of a Deep-STORM model out of a set of pre-trained model for the data processing.\n",
        "\n",
        "<font size = 4> Additionally, AutoDS pipeline splits each input frame into patches and enables processing of different regions in the field-of-view with different models. This mechanism led to an improvment in the reconstruction quality beyond the capabilities of Deep-STORM.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEy4EBXHHyAX"
      },
      "source": [
        "# **Before getting started**\n",
        "---\n",
        "<font size = 4> This notebook contains the code required only for inference of SMLM data using a set of pre-trained Deep-STORM models. For model training please follow this [link](https://github.com/alonsaguy/One-click-image-reconstruction-in-single-molecule-localization-microscopy-via-deep-learning/blob/main/AutoDS/AutoDS_training.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OlaDqH75fdK"
      },
      "source": [
        "# **Run configuration**\n",
        "---\n",
        "<font size = 4>**`Data_folder`:** This folder should contain the images that you want to use your trained network on for processing.\n",
        "\n",
        "<font size = 4>**`Result_folder`:** This folder will contain the found localizations csv.\n",
        "\n",
        "<font size = 4>**`threshold`:** This paramter determines threshold for local maxima finding. A higher `threshold` will result in less localizations. **DEFAULT: 10**\n",
        "\n",
        "<font size = 4>**`neighborhood_size`:** This paramter determines size of the neighborhood within which the prediction needs to be a local maxima in recovery pixels (CCD pixel/upsampling_factor). A high `neighborhood_size` will make the prediction slower and potentially discard nearby localizations. **DEFAULT: 3**\n",
        "\n",
        "<font size = 4>**`use_local_average`:** This paramter determines whether to locally average the prediction in a 3x3 neighborhood to get the final localizations. If set to **True** it will make inference slightly slower depending on the size of the FOV. **DEFAULT: True**\n",
        "\n",
        "<font size = 4>**`num_patches`:** Determines the number of patches in each row and each column after splitting the frames to patches. The total number of patches will be num_patches<sup>2</sup>. **DEFAULT: 4**\n",
        "\n",
        "<font size = 4>**`batch_size`:** This paramter determines how many frames are processed by any single pass on the GPU. A higher `batch_size` will make the prediction faster but will use more GPU memory. If an OutOfMemory (OOM) error occurs, decrease the `batch_size`. **DEFAULT: 1**\n",
        "\n",
        "<font size = 4>**The following parameters are relevant only if `interpolate_based_on_imaging_parameters` is checked:**\n",
        "\n",
        "<font size = 4> - **`pixel_size` [nm]:** the pixels size of the analyzed video. **DEFAULT: 107**\n",
        "\n",
        "<font size = 4> - **`wavelength` [nm]:** the emission wavelength of the analyzed video. **DEFAULT: 715**\n",
        "\n",
        "<font size = 4> - **`numerical_aperture`:** the optical setup numerical aperture of the analyzed video. **DEFAULT: 1.49**\n",
        "\n",
        "<font size = 4> - **`chunk_size`:** determine the number of patches that will be analyzed in each prediction iteration. This parameter is used for managing compute resources in Google Colab. If you are facing crashes due to RAM memory limitation, decrease the number of patches per chunk. **DEFAULT: 10000**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjrvdfQzOdee"
      },
      "source": [
        "# **Mount Google Drive**\n",
        "---\n",
        "Running the next cell will mount your google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RDZ3-WKPQDK"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jbPQ6hRzOdsN"
      },
      "outputs": [],
      "source": [
        "#@markdown Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRnQZWSZhArJ"
      },
      "source": [
        "# **One-click inference**\n",
        "---\n",
        "Running the next cell will perform the following steps:\n",
        "1. Installating require dependencies\n",
        "2. Requesting GPU access\n",
        "3. Downloading pre-trained models\n",
        "4. Running the inference based on your configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSrZMo3X_NhO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "Notebook_version = '1.2'\n",
        "Network = 'AutoDS'\n",
        "\n",
        "# Import keras modules and libraries from tensorflow.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Activation, UpSampling2D, Conv2D, MaxPooling2D, BatchNormalization, Layer\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Other libraries\n",
        "import scipy.optimize as opt\n",
        "import scipy.io as sio\n",
        "import scipy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile as tiff\n",
        "from numpy.lib.stride_tricks import sliding_window_view\n",
        "from scipy.ndimage import gaussian_laplace, maximum_filter, binary_dilation\n",
        "from scipy.signal import fftconvolve\n",
        "from skimage.morphology import white_tophat, disk\n",
        "import h5py\n",
        "import cv2\n",
        "from skimage import io\n",
        "import sys, os, traceback\n",
        "import csv\n",
        "from PIL import Image\n",
        "from PIL.TiffTags import TAGS\n",
        "import math\n",
        "from skimage.feature import peak_local_max\n",
        "from scipy.ndimage import gaussian_filter, zoom\n",
        "from tqdm import tqdm\n",
        "from contextlib import contextmanager\n",
        "\n",
        "# Create a variable to get and store relative base path\n",
        "base_path = os.getcwd()\n",
        "\n",
        "import io, json, zipfile, hashlib, shutil, urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "def _printer():\n",
        "    # use global log() if you defined QUIET/log earlier; else print\n",
        "    return log if 'log' in globals() else print\n",
        "\n",
        "def _sha256(path):\n",
        "    h = hashlib.sha256()\n",
        "    with open(path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def _download(url, dst_path):\n",
        "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "    _printer()(f\"[models] downloading: {url}\")\n",
        "    urllib.request.urlretrieve(url, dst_path)\n",
        "\n",
        "def _flatten_if_needed(target_dir, required_files):\n",
        "    \"\"\"\n",
        "    If the extracted ZIP created a nested top-level folder (e.g., target_dir/diff_1/*),\n",
        "    but we expect files directly under target_dir, move them up one level.\n",
        "    \"\"\"\n",
        "    present = all(os.path.exists(os.path.join(target_dir, f)) for f in required_files)\n",
        "    if present:\n",
        "        return\n",
        "\n",
        "    # look for a single subdir containing the stuff\n",
        "    subdirs = [d for d in os.listdir(target_dir) if os.path.isdir(os.path.join(target_dir, d))]\n",
        "    if len(subdirs) == 1:\n",
        "        candidate = os.path.join(target_dir, subdirs[0])\n",
        "        # if moving would fix it, move contents up\n",
        "        if all(os.path.exists(os.path.join(candidate, f)) for f in required_files):\n",
        "            for name in os.listdir(candidate):\n",
        "                shutil.move(os.path.join(candidate, name), os.path.join(target_dir, name))\n",
        "            # remove now-empty subdir\n",
        "            try:\n",
        "                os.rmdir(candidate)\n",
        "            except OSError:\n",
        "                pass\n",
        "\n",
        "def ensure_models(model_names, target_root=\"/content/AutoDS_models\", model_manifest=None):\n",
        "    \"\"\"\n",
        "    model_manifest schema (choose ONE per model):\n",
        "      # ZIP asset per model (recommended)\n",
        "      {\n",
        "        \"diff_1\": {\n",
        "          \"zip_url\": \"<direct zip url>\",\n",
        "          \"sha256\":  \"<optional sha256 of the zip>\",\n",
        "          \"contains\": [\"best_weights.h5\", \"model_metadata.mat\"]\n",
        "        },\n",
        "        ...\n",
        "      }\n",
        "\n",
        "      # Raw files (no zip)\n",
        "      {\n",
        "        \"diff_1\": {\n",
        "          \"file_urls\": {\n",
        "            \"best_weights.h5\": \"<direct file url>\",\n",
        "            \"model_metadata.mat\": \"<direct file url>\"\n",
        "          },\n",
        "          \"file_sha256\": {             # optional, per-file\n",
        "            \"best_weights.h5\": \"<sha256>\",\n",
        "            \"model_metadata.mat\": \"<sha256>\"\n",
        "          },\n",
        "          \"contains\": [\"best_weights.h5\", \"model_metadata.mat\"]\n",
        "        },\n",
        "        ...\n",
        "      }\n",
        "    \"\"\"\n",
        "    if model_manifest is None:\n",
        "        raise ValueError(\"ensure_models: model_manifest must be provided.\")\n",
        "    os.makedirs(target_root, exist_ok=True)\n",
        "\n",
        "    for m in model_names:\n",
        "        cfg = model_manifest[m]\n",
        "        mdir = os.path.join(target_root, m)\n",
        "        need_fetch = False\n",
        "\n",
        "        # fast-path: check presence\n",
        "        req = cfg.get(\"contains\", [])\n",
        "        if not os.path.isdir(mdir):\n",
        "            need_fetch = True\n",
        "        else:\n",
        "            for f in req:\n",
        "                if not os.path.exists(os.path.join(mdir, f)):\n",
        "                    need_fetch = True\n",
        "                    break\n",
        "\n",
        "        if not need_fetch:\n",
        "            _printer()(f\"[models] found: {m}\")\n",
        "            continue\n",
        "\n",
        "        _printer()(f\"[models] preparing: {m}\")\n",
        "        os.makedirs(mdir, exist_ok=True)\n",
        "\n",
        "        if \"zip_url\" in cfg:\n",
        "            # ZIP flow\n",
        "            zip_url = cfg[\"zip_url\"]\n",
        "            zip_path = os.path.join(target_root, f\"{m}.zip\")\n",
        "            _download(zip_url, zip_path)\n",
        "\n",
        "            if \"sha256\" in cfg:\n",
        "                digest = _sha256(zip_path)\n",
        "                if digest != cfg[\"sha256\"]:\n",
        "                    raise ValueError(f\"SHA256 mismatch for {m} zip. expected {cfg['sha256']} got {digest}\")\n",
        "\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "                zf.extractall(mdir)\n",
        "            os.remove(zip_path)\n",
        "\n",
        "            # handle nested folder cases\n",
        "            _flatten_if_needed(mdir, req)\n",
        "\n",
        "        elif \"file_urls\" in cfg:\n",
        "            # Per-file flow\n",
        "            file_urls = cfg[\"file_urls\"]\n",
        "            file_sha = cfg.get(\"file_sha256\", {})\n",
        "            for fname, url in file_urls.items():\n",
        "                dst = os.path.join(mdir, fname)\n",
        "                _download(url, dst)\n",
        "                if fname in file_sha:\n",
        "                    digest = _sha256(dst)\n",
        "                    if digest != file_sha[fname]:\n",
        "                        raise ValueError(f\"SHA256 mismatch for {m}/{fname}. expected {file_sha[fname]} got {digest}\")\n",
        "        else:\n",
        "            raise ValueError(f\"Model {m} manifest must have either 'zip_url' or 'file_urls'.\")\n",
        "\n",
        "        # Final presence check\n",
        "        for f in req:\n",
        "            if not os.path.exists(os.path.join(mdir, f)):\n",
        "                raise FileNotFoundError(f\"Model {m} missing required file after fetch: {f}\")\n",
        "\n",
        "        _printer()(f\"[models] ready: {m}\")\n",
        "\n",
        "    return target_root\n",
        "\n",
        "# --- Quiet/Preview flags ------------------------------------------------------\n",
        "QUIET = False            # no training/inference chatter unless set to False\n",
        "HEADLESS_PREVIEW = True  # set True if you want to see the preview figures\n",
        "\n",
        "def log(*args, **kwargs):\n",
        "    if not QUIET:\n",
        "        print(*args, **kwargs)\n",
        "\n",
        "# Define where to fetch each model\n",
        "# Replace the example zip URLs with your actual GitHub Release (or other) asset URLs.\n",
        "model_names = ['diff_1', 'diff_2', 'diff_3', 'diff_4']\n",
        "MODEL_MANIFEST = {\n",
        "    \"diff_1\": {\n",
        "        \"file_urls\": {\n",
        "            \"best_weights.h5\": \"https://github.com/alonsaguy/One-click-image-reconstruction-in-single-molecule-localization-microscopy-via-deep-learning/raw/main/AutoDS/models/diff_1/best_weights.h5\",\n",
        "            \"model_metadata.mat\": \"https://github.com/alonsaguy/One-click-image-reconstruction-in-single-molecule-localization-microscopy-via-deep-learning/raw/main/AutoDS/models/diff_1/model_metadata.mat\",\n",
        "        },\n",
        "        \"contains\": [\"best_weights.h5\", \"model_metadata.mat\"]\n",
        "    },\n",
        "    \"diff_2\": {\n",
        "        \"file_urls\": {\n",
        "            \"best_weights.h5\": \"https://github.com/alonsaguy/One-click-image-reconstruction-in-single-molecule-localization-microscopy-via-deep-learning/raw/main/AutoDS/models/diff_2/best_weights.h5\",\n",
        "            \"model_metadata.mat\": \"https://github.com/alonsaguy/One-click-image-reconstruction-in-single-molecule-localization-microscopy-via-deep-learning/raw/main/AutoDS/models/diff_2/model_metadata.mat\",\n",
        "        },\n",
        "        \"contains\": [\"best_weights.h5\", \"model_metadata.mat\"]\n",
        "    },\n",
        "    \"diff_3\": {\n",
        "        \"file_urls\": {\n",
        "            \"best_weights.h5\": \"https://github.com/alonsaguy/One-click-image-reconstruction-in-single-molecule-localization-microscopy-via-deep-learning/raw/main/AutoDS/models/diff_3/best_weights.h5\",\n",
        "            \"model_metadata.mat\": \"https://github.com/alonsaguy/One-click-image-reconstruction-in-single-molecule-localization-microscopy-via-deep-learning/raw/main/AutoDS/models/diff_3/model_metadata.mat\",\n",
        "        },\n",
        "        \"contains\": [\"best_weights.h5\", \"model_metadata.mat\"]\n",
        "    },\n",
        "    \"diff_4\": {\n",
        "        \"file_urls\": {\n",
        "            \"best_weights.h5\": \"https://github.com/alonsaguy/One-click-image-reconstruction-in-single-molecule-localization-microscopy-via-deep-learning/raw/main/AutoDS/models/diff_4/best_weights.h5\",\n",
        "            \"model_metadata.mat\": \"https://github.com/alonsaguy/One-click-image-reconstruction-in-single-molecule-localization-microscopy-via-deep-learning/raw/main/AutoDS/models/diff_4/model_metadata.mat\",\n",
        "        },\n",
        "        \"contains\": [\"best_weights.h5\", \"model_metadata.mat\"]\n",
        "    },\n",
        "}\n",
        "# Download (only if missing) and set prediction_model_path accordingly\n",
        "prediction_model_path = ensure_models(model_names, target_root=\"/content/AutoDS_models\", model_manifest=MODEL_MANIFEST)\n",
        "\n",
        "def correctDriftLocalization(xc_array, yc_array, frames, xDrift, yDrift):\n",
        "  n_locs = xc_array.shape[0]\n",
        "  xc_array_Corr = np.empty(n_locs)\n",
        "  yc_array_Corr = np.empty(n_locs)\n",
        "\n",
        "  for loc in range(n_locs):\n",
        "    xc_array_Corr[loc] = xc_array[loc] - xDrift[frames[loc] - 1]\n",
        "    yc_array_Corr[loc] = yc_array[loc] - yDrift[frames[loc] - 1]\n",
        "\n",
        "  return (xc_array_Corr, yc_array_Corr)\n",
        "\n",
        "def FromLoc2Image_SimpleHistogram(xc_array, yc_array, image_size = (64,64), pixel_size = 100):\n",
        "  w = image_size[0]\n",
        "  h = image_size[1]\n",
        "  locImage = np.zeros((image_size[0],image_size[1]) )\n",
        "  n_locs = len(xc_array)\n",
        "\n",
        "  for e in range(n_locs):\n",
        "    locImage[int(max(min(round(yc_array[e]/pixel_size),w-1),0))][int(max(min(round(xc_array[e]/pixel_size),h-1),0))] += 1\n",
        "\n",
        "  return locImage\n",
        "\n",
        "def estimate_drift_com_nm(img1, img2, pixel_size_nm, sigma=1.0, patch_radius=3):\n",
        "    # Smooth images\n",
        "    img1_smooth = gaussian_filter(img1.astype(np.float32), sigma=sigma)\n",
        "    img2_smooth = gaussian_filter(img2.astype(np.float32), sigma=sigma)\n",
        "\n",
        "    # Cross-correlation\n",
        "    corr = fftconvolve(img1_smooth, img2_smooth, mode='same')\n",
        "\n",
        "    # Define center of the image\n",
        "    center_y, center_x = np.array(corr.shape) // 2\n",
        "\n",
        "    # Define a crop region around the center\n",
        "    y_min = max(0, center_y - patch_radius)\n",
        "    y_max = min(corr.shape[0], center_y + patch_radius + 1)\n",
        "    x_min = max(0, center_x - patch_radius)\n",
        "    x_max = min(corr.shape[1], center_x + patch_radius + 1)\n",
        "\n",
        "    # Crop around center\n",
        "    patch = corr[y_min:y_max, x_min:x_max]\n",
        "\n",
        "    # Find subpixel center of mass in cropped patch\n",
        "    y_grid, x_grid = np.meshgrid(\n",
        "        np.arange(y_min, y_max), np.arange(x_min, x_max), indexing='ij'\n",
        "    )\n",
        "\n",
        "    total = np.sum(patch)\n",
        "    if total == 0:\n",
        "        return 0.0, 0.0\n",
        "\n",
        "    y_com = np.sum(patch * y_grid) / total\n",
        "    x_com = np.sum(patch * x_grid) / total\n",
        "\n",
        "    # Drift relative to center, in pixels\n",
        "    dy_px = y_com - center_y\n",
        "    dx_px = x_com - center_x\n",
        "\n",
        "    # Limit the drift to patch_radius\n",
        "    if abs(dy_px) > patch_radius or abs(dx_px) > patch_radius:\n",
        "        return 0.0, 0.0  # or raise an exception\n",
        "\n",
        "    # Convert to nanometers\n",
        "    dy_nm = dy_px * pixel_size_nm\n",
        "    dx_nm = dx_px * pixel_size_nm\n",
        "\n",
        "    return dy_nm, dx_nm\n",
        "\n",
        "def gaussian_interpolation_batch(data_batch, scale, sigma=1):\n",
        "    \"\"\"\n",
        "    Applies Gaussian interpolation (smoothing and upsampling) to a batch of images.\n",
        "\n",
        "    Parameters:\n",
        "    - data_batch: A numpy array of shape (batch_size, height, width), where each entry is an image.\n",
        "    - scale: The scaling factor for upsampling.\n",
        "    - sigma: The standard deviation for the Gaussian filter (default is 1).\n",
        "\n",
        "    Returns:\n",
        "    - upsampled_data_batch: A numpy array containing the upsampled images.\n",
        "    \"\"\"\n",
        "    upsampled_data_batch = []\n",
        "\n",
        "    for data in data_batch:\n",
        "        # Apply Gaussian filter to each image in the batch\n",
        "        smoothed_data = gaussian_filter(data, sigma=sigma)\n",
        "\n",
        "        # Upsample the smoothed image\n",
        "        upsampled_data = zoom(smoothed_data, scale, order=3)  # Using cubic interpolation for smooth upsampling\n",
        "        upsampled_data_batch.append(upsampled_data)\n",
        "\n",
        "    # Convert the list of upsampled images back into a numpy array\n",
        "    return np.array(upsampled_data_batch)\n",
        "\n",
        "def interpolate_frames(tiff_stack, model_pixel_size, current_pixel_size,\n",
        "                             model_wavelength, current_wavelength, model_NA, current_NA):\n",
        "    # Compute ratio\n",
        "    if model_pixel_size is None: model_pixel_size = current_pixel_size\n",
        "    if model_wavelength is None: model_wavelength = current_wavelength\n",
        "    if model_NA is None: model_NA = current_NA\n",
        "    if current_wavelength is None: current_wavelength = model_wavelength = 1\n",
        "    if current_NA is None: current_NA = model_NA = 1\n",
        "\n",
        "    if len(tiff_stack.shape) == 2:\n",
        "        tiff_stack = tiff_stack[None, :, :]\n",
        "\n",
        "    scale_ratio_sq = (0.21 * model_wavelength / model_NA) ** 2 - (0.21 * current_wavelength / current_NA) ** 2\n",
        "    if (scale_ratio_sq) > 0:\n",
        "        scale_ratio = np.sqrt(scale_ratio_sq) / model_pixel_size\n",
        "        interpolated_stack = np.stack([gaussian_filter(tiff_stack[i], scale_ratio) for i in range(tiff_stack.shape[0])])\n",
        "    else:\n",
        "        zoom_factors = (1, model_pixel_size / current_pixel_size, model_pixel_size / current_pixel_size)\n",
        "        interpolated_stack = zoom(tiff_stack.astype(np.float32), zoom_factors, order=3)\n",
        "\n",
        "    return interpolated_stack.astype(np.float32, copy=False)  # <-- ensure float32\n",
        "\n",
        "def ChooseNetByDifficulty_2025(density, SNR):\n",
        "    num_models = 4\n",
        "    norm_density = np.max([np.min([int(np.round(2 * density)), num_models-1]), 0])\n",
        "    norm_SNR = num_models - 1 - np.max([np.min([SNR//2, num_models - 1]), 0])\n",
        "    return int(np.round((norm_SNR + norm_density) / 2))\n",
        "\n",
        "def reconstruct_patches_2025(Images, patch_ind, frame_numbers, weights_file, num_patches, overlap, number_of_frames,\n",
        "                             thresh=0.1, neighborhood_size=3, use_local_avg=False, upsampling_factor=8, pixel_size=None,\n",
        "                             batch_size=1):\n",
        "    pixel_size_hr = pixel_size / upsampling_factor\n",
        "\n",
        "    # Convert Images to float32 Tensor and move to GPU\n",
        "    Images = tf.convert_to_tensor(Images, dtype=tf.float32)\n",
        "    if Images.ndim == 2:\n",
        "        Images = tf.expand_dims(Images, axis=0)  # Ensure 3D shape\n",
        "    K_frames, M, N = Images.shape\n",
        "\n",
        "    # Determine dimensions of each predicted (cropped) patch.\n",
        "    patch_height = M * upsampling_factor - 2 * overlap\n",
        "    patch_width = N * upsampling_factor - 2 * overlap\n",
        "\n",
        "    # Create full image tensor on GPU\n",
        "    reconstructed_image = np.zeros((patch_height * num_patches, patch_width * num_patches), dtype=np.float32)\n",
        "\n",
        "    # Prepare lists for detections\n",
        "    recon_xind, recon_yind, frame_index, confidence_list = [], [], [], []\n",
        "\n",
        "    # Load the model on the GPU\n",
        "    with tf.device('/GPU:0'):\n",
        "        model = build_model_upsample((M, N, 1), lr=1e-3, upsampling_factor=upsampling_factor)\n",
        "        model.load_weights(weights_file)\n",
        "\n",
        "        # Create the post-processing layer\n",
        "        max_layer = Maximafinder(thresh, neighborhood_size, use_local_avg)\n",
        "\n",
        "        n_batches = int(np.ceil(K_frames / batch_size))\n",
        "        for b in range(n_batches):\n",
        "            start = b * batch_size\n",
        "            end = min(K_frames, start + batch_size)\n",
        "            nF = end - start\n",
        "\n",
        "            # --- Move input batch to GPU ---\n",
        "            batch_imgs = Images[start:end]  # Shape: (nF, M, N)\n",
        "\n",
        "            # --- Run prediction on GPU ---\n",
        "            predicted_density = model(batch_imgs, training=False)\n",
        "            predicted_density = tf.nn.relu(predicted_density - 0.5).numpy()  # Faster than `predicted_density[predicted_density < 0] = 0`\n",
        "\n",
        "            # Crop off extra overlap\n",
        "            cropped_pred = predicted_density[:, overlap:-overlap, overlap:-overlap, 0]\n",
        "\n",
        "            # --- Post-processing on GPU ---\n",
        "            bind, xind, yind, conf = max_layer(predicted_density[:, overlap:-overlap, overlap:-overlap])\n",
        "\n",
        "            # Convert tensors to NumPy (only when needed)\n",
        "            bind_np, xind_np, yind_np, conf_np = bind.numpy(), xind.numpy(), yind.numpy(), conf.numpy() / L2_weighting_factor\n",
        "\n",
        "            # --- Place each patch in reconstructed image ---\n",
        "            for i in range(nF):\n",
        "                p_ind = patch_ind[start + i]\n",
        "                y1 = patch_height * (p_ind // num_patches)\n",
        "                x1 = patch_width * (p_ind % num_patches)\n",
        "\n",
        "                # Use TensorFlow addition instead of NumPy\n",
        "                reconstructed_image[y1:y1 + patch_height, x1:x1 + patch_width] += (cropped_pred[i] / number_of_frames)\n",
        "\n",
        "                # Collect detections\n",
        "                det_idx = np.where(bind_np == i)[0]\n",
        "                if det_idx.size:\n",
        "                    recon_xind.extend((x1 + xind_np[det_idx]).tolist())\n",
        "                    recon_yind.extend((y1 + yind_np[det_idx]).tolist())\n",
        "                    frame_index.extend([frame_numbers[start + i] + 1] * det_idx.size)\n",
        "                    confidence_list.extend(conf_np[det_idx].tolist())\n",
        "\n",
        "    # Convert coordinates to physical units\n",
        "    xind_final = (np.array(recon_xind) * pixel_size_hr).tolist()\n",
        "    yind_final = (np.array(recon_yind) * pixel_size_hr).tolist()\n",
        "\n",
        "    return reconstructed_image, [frame_index, xind_final, yind_final, confidence_list]\n",
        "\n",
        "\n",
        "def split_image_to_patches(img, num_patches, overlap):\n",
        "    # Determine the non-overlapping patch size.\n",
        "    H, W = img.shape\n",
        "    patch_h = H // num_patches\n",
        "    patch_w = W // num_patches\n",
        "\n",
        "    # Pad the image so that border patches have the proper overlap.\n",
        "    padded_img = np.pad(img, ((overlap, overlap), (overlap, overlap)), mode='reflect')\n",
        "\n",
        "    # Define the window (patch) shape including overlap.\n",
        "    window_shape = (patch_h + 2 * overlap, patch_w + 2 * overlap)\n",
        "\n",
        "    # Create a sliding window view of the padded image.\n",
        "    # The sliding window view will have shape:\n",
        "    # (padded_H - window_shape[0] + 1, padded_W - window_shape[1] + 1, window_shape[0], window_shape[1])\n",
        "    patches_view = sliding_window_view(padded_img, window_shape)\n",
        "\n",
        "    # Sample patches at strides equal to the basic patch size.\n",
        "    patches_array = patches_view[0::patch_h, 0::patch_w, :, :]\n",
        "\n",
        "    # Flatten the 2D grid of patches (row-major order) into a list.\n",
        "    num_rows, num_cols, ph, pw = patches_array.shape\n",
        "    patches_list = [patches_array[i, j].copy() for i in range(num_rows) for j in range(num_cols)]\n",
        "\n",
        "    return patches_list\n",
        "\n",
        "def gauss2d(xy, offset, amp, x0, y0, sigma):\n",
        "  x, y = xy\n",
        "  return offset + (amp * np.exp(-((x - x0) ** 2) / (2 * sigma ** 2) - ((y - y0) ** 2) / (2 * sigma ** 2)))\n",
        "\n",
        "def extract_all_features(Images, FOV_size, pixel_size):\n",
        "    M, N = FOV_size\n",
        "    patch_size = 7\n",
        "    xy = np.zeros([2, int(patch_size ** 2)])\n",
        "    for i1 in range(patch_size):\n",
        "        for j1 in range(patch_size):\n",
        "            xy[:, int(i1 + patch_size * j1)] = [i1, j1]\n",
        "\n",
        "    if(len(Images.shape) == 2):\n",
        "        Images = Images[None, :, :]\n",
        "\n",
        "    peaks_first_frame = peak_local_max(Images[0],\n",
        "                                       min_distance=patch_size // 2,\n",
        "                                       threshold_abs=np.mean(Images[0]) + np.std(Images[0]))\n",
        "    peaks_for_analysis = []\n",
        "    cnt = 0\n",
        "    for i in range(len(peaks_first_frame)):\n",
        "        if (np.sum(np.abs(peaks_first_frame[:, 0] - peaks_first_frame[i, 0]) +\n",
        "                   np.abs(peaks_first_frame[:, 1] - peaks_first_frame[i, 1]) < 2) == 1):\n",
        "            peaks_for_analysis.append([peaks_first_frame[cnt, 0], peaks_first_frame[cnt, 1]])\n",
        "            cnt += 1\n",
        "            if (cnt > 100):\n",
        "                break\n",
        "\n",
        "    peaks_for_analysis = np.array(peaks_for_analysis)\n",
        "    number_of_PSFs_to_fit = np.min([100, peaks_for_analysis.shape[0]])\n",
        "\n",
        "    sigmas_list = []\n",
        "    gaussian_amp_list = []\n",
        "    for i in range(number_of_PSFs_to_fit):\n",
        "        down = np.max([0, peaks_for_analysis[i, 0] - patch_size // 2])\n",
        "        up = np.min([M - 1, peaks_for_analysis[i, 0] + patch_size // 2])\n",
        "        left = np.max([0, peaks_for_analysis[i, 1] - patch_size // 2])\n",
        "        right = np.min([N - 1, peaks_for_analysis[i, 1] + patch_size // 2])\n",
        "        zobs = (Images[0][down:up + 1, left:right + 1]).reshape(1, -1).squeeze()\n",
        "        try:\n",
        "            guess = [np.median(zobs), np.median(zobs), patch_size // 2, patch_size // 2, 1]\n",
        "            bounds = ([0, 0, 0, 0, 0.5], [np.inf, np.inf, patch_size, patch_size, patch_size // 2])\n",
        "            pred_params, uncert_cov = opt.curve_fit(gauss2d, xy, zobs, p0=guess, bounds=bounds)\n",
        "        except Exception as e:\n",
        "            continue\n",
        "        fit = gauss2d(xy, *pred_params)\n",
        "        if (1 - np.sqrt(np.mean((zobs / np.max(zobs) - fit / np.max(fit)) ** 2)) < 0.9):\n",
        "           continue\n",
        "        sigmas_list.append(pred_params[4])\n",
        "        gaussian_amp_list.append(pred_params[1])\n",
        "\n",
        "    if(len(sigmas_list) < 1):\n",
        "        log(\"Did not find emitters for sigma estimation! setting sigma to 1 pixel\")\n",
        "        sigma = 1\n",
        "        sigma_std = 0\n",
        "    else:\n",
        "        sigma = np.mean(sigmas_list)\n",
        "        sigma_std = np.std(sigmas_list)\n",
        "\n",
        "    mean_noise_list = []\n",
        "    std_noise_list = []\n",
        "    emitter_density_list = []\n",
        "    for i in range(np.min([Images.shape[0], 100])):\n",
        "        curr_mean_noise, curr_std_noise, signal_amp, curr_emitter_density = extract_features_frame(Images[i],\n",
        "                                                                                                   pixel_size,\n",
        "                                                                                                   verbose=False)\n",
        "        mean_noise_list.append(curr_mean_noise)\n",
        "        std_noise_list.append(curr_std_noise)\n",
        "        emitter_density_list.append(curr_emitter_density)\n",
        "\n",
        "    ADC_offset = np.mean(mean_noise_list)\n",
        "    ReadOutNoise_ADC = np.mean(std_noise_list)\n",
        "    gaussian_amp_mean = np.mean(gaussian_amp_list)\n",
        "    gaussian_amp_std = np.std(gaussian_amp_list)\n",
        "    emitter_density = np.mean(emitter_density_list)\n",
        "\n",
        "    return ADC_offset, ReadOutNoise_ADC, gaussian_amp_mean, gaussian_amp_std, \\\n",
        "           emitter_density, sigma, sigma_std\n",
        "\n",
        "def remove_zero_padding(image):\n",
        "    image_array = np.array(image)\n",
        "    non_zero_rows = np.where(image_array.sum(axis=1) != 0)\n",
        "    non_zero_cols = np.where(image_array.sum(axis=0) != 0)\n",
        "    cropped_image = image_array[non_zero_rows[0][0]:non_zero_rows[0][-1]+1, non_zero_cols[0][0]:non_zero_cols[0][-1]+1]\n",
        "    return cropped_image\n",
        "\n",
        "def subtract_smooth_background(im, sigma=3):\n",
        "    return im - gaussian_filter(im, sigma)\n",
        "\n",
        "def subtract_background_tophat(im, radius=15):\n",
        "    return white_tophat(im, footprint=disk(radius))\n",
        "\n",
        "def extract_features_frame(OrigImage, pixel_size, psf_sigma, offset=None, verbose=False):\n",
        "    M, N = OrigImage.shape\n",
        "\n",
        "    Image = OrigImage - gaussian_filter(OrigImage, sigma=5)\n",
        "\n",
        "    if(offset is not None):\n",
        "        if(np.percentile(gaussian_filter(Image, 2), 99) < 2 * Image.mean() or np.percentile(OrigImage, 99) < 2 * offset):\n",
        "            if(verbose):\n",
        "                plt.figure(figsize=(7, 7))\n",
        "                plt.title(\"SNR is too low - ignoring patch\")\n",
        "                plt.imshow(OrigImage)\n",
        "                plt.show()\n",
        "            return np.mean(OrigImage), np.std(OrigImage), 0, 0\n",
        "\n",
        "    log_image = -gaussian_laplace(Image, sigma=psf_sigma)  # negative = blob-like peaks\n",
        "\n",
        "    # Local maxima filtering\n",
        "    neighborhood_size = 3\n",
        "    local_max = (log_image == maximum_filter(log_image, size=neighborhood_size))\n",
        "\n",
        "    # Compute the threshold\n",
        "    amp_threshold = np.mean(Image) + 0.5 * (np.percentile(Image, 99) - np.mean(Image))\n",
        "\n",
        "    # Apply intensity threshold\n",
        "    pcntl_threshold = np.percentile(Image, 85)\n",
        "    binary_mask = np.logical_and(local_max, Image > np.max([amp_threshold, pcntl_threshold]))\n",
        "\n",
        "    dilated_mask = binary_dilation(binary_mask, structure=np.ones((5, 5)))\n",
        "    noise_mask = np.ones_like(binary_mask)\n",
        "    noise_mask[dilated_mask] = 0\n",
        "\n",
        "    if(np.sum(binary_mask) > 0):\n",
        "        ADC_offset = np.mean(OrigImage[noise_mask])\n",
        "        ReadOutNoise_ADC = np.std(OrigImage[noise_mask])\n",
        "        Signal_amp = np.mean(OrigImage[binary_mask == 1])\n",
        "        emitter_density = (10 ** 6) * float(np.sum(binary_mask)) / (M * N * pixel_size ** 2)\n",
        "    else:\n",
        "        if(verbose):\n",
        "            log(\"Didn't find any emitters\")\n",
        "        return np.mean(OrigImage), np.std(OrigImage), 0, 0\n",
        "\n",
        "    if(Signal_amp / ADC_offset < 2.5):\n",
        "        if(emitter_density > 2):\n",
        "            if(verbose):\n",
        "                plt.figure(figsize=(8, 8))\n",
        "                plt.title(\"SNR is too low for emitter density estimation\")\n",
        "                plt.imshow(OrigImage)\n",
        "                plt.show()\n",
        "\n",
        "            return ADC_offset, ReadOutNoise_ADC, Signal_amp, 0\n",
        "\n",
        "    if(verbose):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(131)\n",
        "        plt.imshow(OrigImage)\n",
        "        plt.title(\"Offset = {}\".format(offset))\n",
        "        plt.subplot(132)\n",
        "        plt.imshow(binary_mask)\n",
        "        plt.title(\"signal mask - emitter density {:.3f}\".format(emitter_density))\n",
        "        plt.subplot(133)\n",
        "        plt.imshow(noise_mask)\n",
        "        plt.title(\"noise mask - SNR pred {:.3f}\".format(Signal_amp / ADC_offset))\n",
        "        plt.show()\n",
        "\n",
        "    return ADC_offset, ReadOutNoise_ADC, Signal_amp, emitter_density\n",
        "\n",
        "def project_01(im):\n",
        "    im = np.squeeze(im)\n",
        "    min_val = im.min()\n",
        "    max_val = im.max()\n",
        "    return (im - min_val)/(max_val - min_val)\n",
        "\n",
        "def project_01_ret_vals(im):\n",
        "    im = np.squeeze(im)\n",
        "    min_val = im.min()\n",
        "    max_val = im.max()\n",
        "    return (im - min_val)/(max_val - min_val), min_val, max_val\n",
        "\n",
        "def normalize_im(im, dmean, dstd):\n",
        "    im = np.squeeze(im)\n",
        "    return (im - dmean)/dstd\n",
        "\n",
        "def conv_bn_relu(nb_filter, rk, ck, name):\n",
        "    def f(input_tensor):\n",
        "        conv = Conv2D(nb_filter, kernel_size=(rk, ck), strides=(1,1),\n",
        "                      padding=\"same\", use_bias=False,\n",
        "                      kernel_initializer=\"Orthogonal\", name='conv-'+name)(input_tensor)\n",
        "        conv_norm = BatchNormalization(name='BN-'+name)(conv)\n",
        "        conv_norm_relu = Activation(\"relu\", name='Relu-'+name)(conv_norm)\n",
        "        return conv_norm_relu\n",
        "    return f\n",
        "\n",
        "def CNN(input_tensor, names):\n",
        "    Features1 = conv_bn_relu(32,3,3,names+'F1')(input_tensor)\n",
        "    pool1 = MaxPooling2D(pool_size=(2,2), name=names+'Pool1')(Features1)\n",
        "    Features2 = conv_bn_relu(64,3,3,names+'F2')(pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2), name=names+'Pool2')(Features2)\n",
        "    Features3 = conv_bn_relu(128,3,3,names+'F3')(pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2), name=names+'Pool3')(Features3)\n",
        "    Features4 = conv_bn_relu(512,3,3,names+'F4')(pool3)\n",
        "    up5 = UpSampling2D(size=(2, 2), name=names+'Upsample1')(Features4)\n",
        "    Features5 = conv_bn_relu(128,3,3,names+'F5')(up5)\n",
        "    up6 = UpSampling2D(size=(2, 2), name=names+'Upsample2')(Features5)\n",
        "    Features6 = conv_bn_relu(64,3,3,names+'F6')(up6)\n",
        "    up7 = UpSampling2D(size=(2, 2), name=names+'Upsample3')(Features6)\n",
        "    Features7 = conv_bn_relu(32,3,3,names+'F7')(up7)\n",
        "    return Features7\n",
        "\n",
        "def buildModel(input_dim, initial_learning_rate=0.001):\n",
        "    input_ = Input(shape=input_dim)\n",
        "    act_ = CNN(input_, 'CNN')\n",
        "    density_pred = Conv2D(1, kernel_size=(1, 1), strides=(1, 1), padding=\"same\",\n",
        "                           activation=\"linear\", use_bias=False,\n",
        "                           kernel_initializer=\"Orthogonal\", name='Prediction')(act_)\n",
        "    model = Model(inputs=input_, outputs=density_pred)\n",
        "    opt = Adam(learning_rate=initial_learning_rate)\n",
        "    model.compile(optimizer=opt, loss=L1L2loss(input_dim))\n",
        "    return model\n",
        "\n",
        "def CNN_upsample(input, upsampling_factor):\n",
        "    # Encoder\n",
        "    x = Conv2D(32, (3, 3), padding='same', name=\"F1\")(input)\n",
        "    x = BatchNormalization(name=\"BN_1\")(x)\n",
        "    x = Activation('relu',name=\"ReLU_1\")(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', name=\"F2\")(x)\n",
        "    x = BatchNormalization(name=\"BN_2\")(x)\n",
        "    x = Activation('relu', name=\"ReLU_2\")(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same', name=\"F3\")(x)\n",
        "    x = BatchNormalization(name=\"BN_3\")(x)\n",
        "    x = Activation('relu', name=\"ReLU_3\")(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name=\"F4\")(x)\n",
        "    x = BatchNormalization(name=\"BN_4\")(x)\n",
        "    x = Activation('relu', name=\"ReLU_4\")(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = Conv2D(128, (3, 3), padding='same', name=\"F5\")(x)\n",
        "    x = BatchNormalization(name=\"BN_5\")(x)\n",
        "    x = Activation('relu', name=\"ReLU_5\")(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', name=\"F6\")(x)\n",
        "    x = BatchNormalization(name=\"BN_6\")(x)\n",
        "    x = Activation('relu', name=\"ReLU_6\")(x)\n",
        "\n",
        "    for ind, scale in enumerate(range(int(np.log2(upsampling_factor)))):\n",
        "        x = UpSampling2D(size=(2, 2), interpolation='bilinear', name=\"upsample_{}\".format(ind+1))(x)\n",
        "        x = Conv2D(32, (5, 5), padding='same', name=\"conv_upsample{}\".format(ind+1))(x)\n",
        "        x = BatchNormalization(name=\"BN_upsample{}\".format(ind+1))(x)\n",
        "        x = Activation('relu', name=\"ReLU_upsample{}\".format(ind+1))(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def build_model_upsample(input_shape, lr=0.001, upsampling_factor=2):\n",
        "    input_ = Input(shape=input_shape)\n",
        "    act_ = CNN_upsample(input_, upsampling_factor)\n",
        "    density_pred = Conv2D(1, kernel_size=(1, 1), strides=(1, 1), padding=\"same\",\n",
        "                                  activation=\"linear\", use_bias = False,\n",
        "                                  kernel_initializer=\"Orthogonal\",name='Prediction')(act_)\n",
        "    model = Model(inputs= input_, outputs=density_pred)\n",
        "    opt = Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=opt, loss = custom_loss(input_shape))\n",
        "    return model\n",
        "\n",
        "def custom_loss(input_shape):\n",
        "    def loss_fn(y_true, y_pred):\n",
        "        heatmap_pred = tf.nn.conv2d(y_pred, gfilter, strides=1, padding='SAME')\n",
        "        loss_heatmaps = tf.reduce_mean(tf.square(y_true - heatmap_pred))\n",
        "        loss_spikes = tf.reduce_mean(tf.abs(y_pred))\n",
        "        return loss_heatmaps + loss_spikes\n",
        "\n",
        "    return loss_fn\n",
        "\n",
        "def matlab_style_gauss2D(shape=(7,7), sigma=1):\n",
        "    m, n = [(ss-1.)/2. for ss in shape]\n",
        "    y, x = np.ogrid[-m:m+1, -n:n+1]\n",
        "    h = np.exp( -(x*x + y*y) / (2.*sigma*sigma) )\n",
        "    h = h.astype(K.floatx())\n",
        "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
        "    sumh = h.sum()\n",
        "    if sumh != 0:\n",
        "        h /= sumh\n",
        "    h = h * 2.0\n",
        "    h = h.astype('float32')\n",
        "    return h\n",
        "\n",
        "# Expand the filter dimensions\n",
        "psf_heatmap = matlab_style_gauss2D(shape=(7,7), sigma=1)\n",
        "gfilter = tf.reshape(psf_heatmap, [7, 7, 1, 1])\n",
        "\n",
        "# Combined MSE + L1 loss\n",
        "def L1L2loss(input_shape):\n",
        "    def bump_mse(heatmap_true, spikes_pred):\n",
        "        heatmap_pred = K.conv2d(spikes_pred, gfilter, strides=(1, 1), padding='same')\n",
        "        loss_heatmaps = losses.mean_squared_error(heatmap_true, heatmap_pred)\n",
        "        loss_spikes = losses.mean_absolute_error(spikes_pred, tf.zeros(input_shape))\n",
        "        return loss_heatmaps + loss_spikes\n",
        "    return bump_mse\n",
        "\n",
        "def getPixelSizeTIFFmetadata(TIFFpath, display=False):\n",
        "  with Image.open(TIFFpath) as img:\n",
        "    meta_dict = {TAGS[key] : img.tag[key] for key in img.tag.keys()}\n",
        "\n",
        "  ResolutionUnit = meta_dict['ResolutionUnit'][0]\n",
        "  width = meta_dict['ImageWidth'][0]\n",
        "  height = meta_dict['ImageLength'][0]\n",
        "  xResolution = meta_dict['XResolution'][0]\n",
        "  if len(xResolution) == 1:\n",
        "    xResolution = xResolution[0]\n",
        "  elif len(xResolution) == 2:\n",
        "    xResolution = xResolution[0]/xResolution[1]\n",
        "  else:\n",
        "    log('Image resolution not defined.')\n",
        "    xResolution = 1\n",
        "\n",
        "  if ResolutionUnit == 2:\n",
        "    pixel_size = 0.025*1e9/xResolution\n",
        "  elif ResolutionUnit == 3:\n",
        "    pixel_size = 0.01*1e9/xResolution\n",
        "  else:\n",
        "    log('Resolution unit not defined. Assuming: um')\n",
        "    pixel_size = 1e3/xResolution\n",
        "\n",
        "  if display:\n",
        "    log('Pixel size obtained from metadata: '+str(pixel_size)+' nm')\n",
        "    log('Image size: '+str(width)+'x'+str(height))\n",
        "\n",
        "  return (pixel_size, width, height)\n",
        "\n",
        "def saveAsTIF(path, filename, array, pixel_size):\n",
        "  if (array.dtype == np.uint16):\n",
        "    mode = 'I;16'\n",
        "  elif (array.dtype == np.uint32):\n",
        "    mode = 'I'\n",
        "  else:\n",
        "    mode = 'F'\n",
        "\n",
        "  if len(array.shape) == 2:\n",
        "    im = Image.fromarray(array)\n",
        "    im.save(os.path.join(path, filename+'.tif'),\n",
        "                  mode=mode,\n",
        "                  resolution_unit=3,\n",
        "                  resolution=0.01*1e9/pixel_size)\n",
        "  elif len(array.shape) == 3:\n",
        "    imlist = []\n",
        "    for frame in array:\n",
        "      imlist.append(Image.fromarray(frame))\n",
        "    imlist[0].save(os.path.join(path, filename+'.tif'), save_all=True,\n",
        "                  append_images=imlist[1:],\n",
        "                  mode=mode,\n",
        "                  resolution_unit=3,\n",
        "                  resolution=0.01*1e9/pixel_size)\n",
        "  return\n",
        "\n",
        "class Maximafinder(Layer):\n",
        "    def __init__(self, thresh, neighborhood_size, use_local_avg, **kwargs):\n",
        "        super(Maximafinder, self).__init__(**kwargs)\n",
        "        self.thresh = tf.constant(thresh, dtype=tf.float32)\n",
        "        self.nhood = neighborhood_size\n",
        "        self.use_local_avg = use_local_avg\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.use_local_avg:\n",
        "          self.kernel_x = tf.reshape(tf.constant([[-1,0,1],[-1,0,1],[-1,0,1]], dtype=tf.float32), [3, 3, 1, 1])\n",
        "          self.kernel_y = tf.reshape(tf.constant([[-1,-1,-1],[0,0,0],[1,1,1]], dtype=tf.float32), [3, 3, 1, 1])\n",
        "          self.kernel_sum = tf.reshape(tf.constant([[1,1,1],[1,1,1],[1,1,1]], dtype=tf.float32), [3, 3, 1, 1])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        max_pool_image = MaxPooling2D(pool_size=(self.nhood,self.nhood), strides=(1,1), padding='same')(inputs)\n",
        "        cond = tf.math.greater(max_pool_image, self.thresh) & tf.math.equal(max_pool_image, inputs)\n",
        "        indices = tf.where(cond)\n",
        "        bind, xind, yind = indices[:, 0], indices[:, 2], indices[:, 1]\n",
        "        confidence = tf.gather_nd(inputs, indices)\n",
        "\n",
        "        if self.use_local_avg:\n",
        "          x_image = K.conv2d(inputs, self.kernel_x, padding='same')\n",
        "          y_image = K.conv2d(inputs, self.kernel_y, padding='same')\n",
        "          sum_image = K.conv2d(inputs, self.kernel_sum, padding='same')\n",
        "          confidence = tf.cast(tf.gather_nd(sum_image, indices), dtype=tf.float32)\n",
        "          x_local = tf.math.divide(tf.gather_nd(x_image, indices), tf.gather_nd(sum_image, indices))\n",
        "          y_local = tf.math.divide(tf.gather_nd(y_image, indices), tf.gather_nd(sum_image, indices))\n",
        "          xind = tf.cast(xind, dtype=tf.float32) + tf.cast(x_local, dtype=tf.float32)\n",
        "          yind = tf.cast(yind, dtype=tf.float32) + tf.cast(y_local, dtype=tf.float32)\n",
        "        else:\n",
        "          xind = tf.cast(xind, dtype=tf.float32)\n",
        "          yind = tf.cast(yind, dtype=tf.float32)\n",
        "\n",
        "        return bind, xind, yind, confidence\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super(Maximafinder, self).get_config()\n",
        "        config = {}\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "def iter_tiff_frames(path):\n",
        "    \"\"\"Yield frames (float32 HxW) and return total count at the end.\"\"\"\n",
        "    with tiff.TiffFile(path) as tif:\n",
        "        number_of_frames = len(tif.pages)\n",
        "        for page in tif.pages:\n",
        "            yield page.asarray().astype(np.float32)\n",
        "    # Generator style; the caller should separately track count if needed.\n",
        "\n",
        "def count_tiff_frames(path):\n",
        "    with tiff.TiffFile(path) as tif:\n",
        "        return len(tif.pages)\n",
        "\n",
        "# --- ND2 helpers: detection, frame count, and per-frame iterator ---\n",
        "\n",
        "def is_nd2(path: str) -> bool:\n",
        "    try:\n",
        "        import nd2\n",
        "        return nd2.is_supported_file(path)\n",
        "    except Exception:\n",
        "        return path.lower().endswith(\".nd2\")\n",
        "\n",
        "\n",
        "def count_nd2_frames(path: str) -> int:\n",
        "    import nd2\n",
        "    with nd2.ND2File(path) as f:\n",
        "        # Preferred: number of sequence frames in the file\n",
        "        try:\n",
        "            return len(f.loop_indices)            # robust across T/Z/C acquisitions\n",
        "        except Exception:\n",
        "            # Fallback: product of looped axes\n",
        "            sz = getattr(f, \"sizes\", {}) or {}\n",
        "            prod = 1\n",
        "            for ax in (\"T\", \"Z\", \"C\", \"V\"):       # V = positions/fields\n",
        "                prod *= int(sz.get(ax, 1))\n",
        "            return prod\n",
        "\n",
        "\n",
        "def _nd2_to_2d(arr, channel=None):\n",
        "    \"\"\"\n",
        "    Convert an ND2 frame (which may be 2D or 3D) to a 2D grayscale image.\n",
        "    - If RGB (Y,X,3/4) -> take channel 0 (or specified)\n",
        "    - If channels-first (C,Y,X) -> take channel 0 (or specified)\n",
        "    - Otherwise squeeze or mean as a last resort.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    a = np.asarray(arr)\n",
        "    if a.ndim == 2:\n",
        "        return a\n",
        "    if a.ndim == 3:\n",
        "        # (Y, X, C) RGB or multi-channel last\n",
        "        if a.shape[-1] in (1, 3, 4):\n",
        "            idx = channel if (channel is not None and channel < a.shape[-1]) else 0\n",
        "            return a[..., idx]\n",
        "        # (C, Y, X) channels-first\n",
        "        if a.shape[0] in (1, 3, 4):\n",
        "            idx = channel if (channel is not None and channel < a.shape[0]) else 0\n",
        "            return a[idx, ...]\n",
        "        # Unknown 3D (e.g., tiny Z), collapse politely\n",
        "        return a.mean(axis=0)\n",
        "    # Any other shape: squeeze to best-effort 2D\n",
        "    a = a.squeeze()\n",
        "    return a if a.ndim == 2 else a.reshape(a.shape[-2], a.shape[-1])\n",
        "\n",
        "def iter_nd2_frames(path: str, channel: int | None = None):\n",
        "    import nd2, numpy as np\n",
        "    n = count_nd2_frames(path)\n",
        "    with nd2.ND2File(path) as f:\n",
        "        for i in range(n):\n",
        "            fr = f.read_frame(i)\n",
        "            fr2d = _nd2_to_2d(fr, channel=channel)\n",
        "            yield fr2d.astype(np.float32, copy=False)   # <-- ensure float32\n",
        "\n",
        "def getPixelSizeND2metadata(path, display=False):\n",
        "    import nd2\n",
        "    with nd2.ND2File(path) as f:\n",
        "        vox_um = getattr(f, \"voxel_size\", None)   # (z, y, x) in microns, when available\n",
        "        if vox_um is None:\n",
        "            return None, None, None\n",
        "        px_nm = vox_um[2] * 1e3                   # x pixel size in nm\n",
        "        # Width/height available from attributes/shape\n",
        "        try:\n",
        "            h, w = f.shape[-2], f.shape[-1]       # (Y, X) at the end\n",
        "        except Exception:\n",
        "            h = w = None\n",
        "        if display:\n",
        "            print(f\"Pixel size (ND2): {px_nm:.2f} nm | image ~ {w}x{h}\")\n",
        "        return px_nm, w, h\n",
        "\n",
        "def list_files_multi(directory, extensions):\n",
        "    exts = {('.' + e.lower()) for e in extensions}\n",
        "    for f in os.listdir(directory):\n",
        "        if os.path.splitext(f)[1].lower() in exts:\n",
        "            yield f\n",
        "\n",
        "def list_files(directory, extension):\n",
        "  return (f for f in os.listdir(directory) if f.endswith('.' + extension))\n",
        "\n",
        "log('--------------------------------')\n",
        "log('AutoDS installation complete.')\n",
        "\n",
        "if tf.test.gpu_device_name() == '':\n",
        "  log('You do not have GPU access.')\n",
        "  log('Did you change your runtime?')\n",
        "  log('If the runtime settings are correct then GPU might not be allocated to your session.')\n",
        "  log('Expect slow performance. To access GPU try reconnecting later.')\n",
        "else:\n",
        "  log('You have GPU access')\n",
        "\n",
        "log('Tensorflow version is ' + str(tf.__version__))\n",
        "\n",
        "MAX_FILE_GB = 5.0  # warn & skip when file is larger than this\n",
        "\n",
        "def _is_oom(exc: BaseException) -> bool:\n",
        "    msg = (str(exc) or \"\").upper()\n",
        "    return (\n",
        "        isinstance(exc, tf.errors.ResourceExhaustedError) or\n",
        "        isinstance(exc, MemoryError) or\n",
        "        \"OUT OF MEMORY\" in msg or \"OOM\" in msg or\n",
        "        exc.__class__.__name__ in {\"_ArrayMemoryError\"}\n",
        "    )\n",
        "\n",
        "@contextmanager\n",
        "def catch_oom(phase: str, detail: str = \"\", on_oom=\"continue\"):\n",
        "    \"\"\"\n",
        "    Wrap any memory-heavy block. Prints a friendly message on OOM and continues.\n",
        "    on_oom: \"continue\" (default) just prints and returns; any other value re-raises.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        yield\n",
        "    except Exception as e:\n",
        "        if _is_oom(e):\n",
        "            print(f\"\\n  OOM while {phase}{(' - ' + detail) if detail else ''}.\")\n",
        "            print(\"   Tip: reduce chunk_size/batch_size/upsampling, or downsample input.\")\n",
        "            if isinstance(e, tf.errors.ResourceExhaustedError) and getattr(e, \"message\", None):\n",
        "                print(\"   TensorFlow says:\", e.message.splitlines()[0][:200])\n",
        "            else:\n",
        "                traceback.print_exc(limit=1, file=sys.stdout)\n",
        "            if on_oom != \"continue\":\n",
        "                raise\n",
        "        else:\n",
        "            # Non-OOM: re-raise so real bugs are visible\n",
        "            raise\n",
        "\n",
        "verbose = False\n",
        "# ------------------------------- User input -------------------------------\n",
        "Data_folder = \"\"  #@param {type:\"string\"}\n",
        "Result_folder = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "threshold = 10 #@param {type:\"number\"}\n",
        "neighborhood_size = 3 #@param {type:\"integer\"}\n",
        "use_local_average = False #@param {type:\"boolean\"}\n",
        "\n",
        "num_patches = 4 #@param {type:\"number\"}\n",
        "overlap = 4\n",
        "batch_size = 1 #@param {type:\"integer\"}\n",
        "\n",
        "interpolate_based_on_imaging_parameters = True #@param {type:\"boolean\"}\n",
        "get_pixel_size_from_file = False #@param {type:\"boolean\"}\n",
        "pixel_size = 107 #@param {type:\"number\"}\n",
        "wavelength = 715 #@param {type:\"number\"}\n",
        "numerical_aperture = 1.49 #@param {type:\"number\"}\n",
        "\n",
        "chunk_size = 10000 #@param {type:\"number\"}\n",
        "\n",
        "psf_sigma_nm = 0.21 * wavelength / numerical_aperture\n",
        "psf_sigma_pixels = psf_sigma_nm / pixel_size\n",
        "\n",
        "if get_pixel_size_from_file:\n",
        "  pixel_size = None\n",
        "\n",
        "matfile = sio.loadmat(os.path.join(prediction_model_path, model_names[0], 'model_metadata.mat'))\n",
        "try:\n",
        "    model_wavelength = np.array(matfile['wavelength'].item())\n",
        "except:\n",
        "    model_wavelength = None\n",
        "try:\n",
        "    model_NA = np.array(matfile['numerical_aperture'].item())\n",
        "except:\n",
        "    model_NA = None\n",
        "try:\n",
        "    model_pixel_size = np.array(matfile['pixel_size'].item())\n",
        "except:\n",
        "    model_pixel_size = None\n",
        "\n",
        "if os.path.isdir(Data_folder):\n",
        "    # iterate both TIFF and ND2\n",
        "    for filename in list_files_multi(Data_folder, extensions=['tif','tiff','nd2']):\n",
        "\n",
        "        # Install nd2 reader only when needed (optional)\n",
        "        if filename.lower().endswith('.nd2'):\n",
        "            try:\n",
        "                import nd2  # already installed?\n",
        "            except Exception:\n",
        "                # Jupyter-only magic; remove if not on Colab\n",
        "                get_ipython().system('pip install -q nd2')\n",
        "\n",
        "        in_path = os.path.join(Data_folder, filename)\n",
        "\n",
        "        # --------- file size guard ----------\n",
        "        try:\n",
        "            file_size_gb = os.path.getsize(in_path) / 1e9\n",
        "            if file_size_gb > MAX_FILE_GB:\n",
        "                print(f\"\\n  {filename}: {file_size_gb:.2f} GB > {MAX_FILE_GB:.2f} GB.\")\n",
        "                print(\"   Video size is too big, please use Google Colab Pro or run locally.\")\n",
        "                continue\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # --- Resolve pixel size if requested ---\n",
        "        if get_pixel_size_from_file:\n",
        "            if is_tiff(in_path):\n",
        "                with catch_oom(\"reading TIFF pixel size\", filename):\n",
        "                    pixel_size, _, _ = getPixelSizeTIFFmetadata(in_path, True)\n",
        "            elif is_nd2(in_path):\n",
        "                with catch_oom(\"reading ND2 pixel size\", filename):\n",
        "                    px_nm, _, _ = getPixelSizeND2metadata(in_path, True)\n",
        "                    pixel_size = px_nm if px_nm is not None else pixel_size  # leave unchanged if unknown\n",
        "\n",
        "        # --- Common model params ---\n",
        "        upsampling_factor = np.array(matfile['upsampling_factor']).item()\n",
        "        try:\n",
        "            L2_weighting_factor = np.array(matfile['Normalization factor']).item()\n",
        "        except:\n",
        "            L2_weighting_factor = 100\n",
        "\n",
        "        patches_list = [[] for _ in model_names]\n",
        "        patch_indices_list = [[] for _ in model_names]\n",
        "        frame_numbers = [[] for _ in model_names]\n",
        "\n",
        "        # --- Choose reader & frame count ---\n",
        "        number_of_frames, frame_iter = None, None\n",
        "        with catch_oom(\"opening stack\", filename):\n",
        "            if is_tiff(in_path):\n",
        "                number_of_frames = count_tiff_frames(in_path)\n",
        "                frame_iter = iter_tiff_frames(in_path)\n",
        "                log(f'Loaded tiff stack with {number_of_frames} frames')\n",
        "            elif is_nd2(in_path):\n",
        "                number_of_frames = count_nd2_frames(in_path)\n",
        "                frame_iter = iter_nd2_frames(in_path)\n",
        "                log(f'Loaded ND2 stack with ~{number_of_frames} planes (T*Z*C)')\n",
        "            else:\n",
        "                log(f\"Skipping unsupported file: {filename}\")\n",
        "\n",
        "        if frame_iter is None:\n",
        "            print(f\"  Skipping {filename} due to earlier error.\")\n",
        "            continue\n",
        "\n",
        "        # Initialize sum image lazily\n",
        "        sum_image = None\n",
        "\n",
        "        log('Splitting stack to patches and selecting Deep-STORM model')\n",
        "        for i, frame in enumerate(tqdm(frame_iter, total=number_of_frames if number_of_frames else None)):\n",
        "\n",
        "            if sum_image is None:\n",
        "                with catch_oom(\"allocating preview buffer\", f\"{filename} sum_image\"):\n",
        "                    sum_image = np.zeros_like(frame, dtype=np.float32)\n",
        "                    # if allocation failed, sum_image stays None and we skip this file\n",
        "                    if sum_image is None:\n",
        "                        print(f\"  Skipping {filename}: failed to allocate preview buffer.\")\n",
        "                        break\n",
        "\n",
        "            # Keep a running average for preview\n",
        "            with catch_oom(\"accumulating preview\", f\"{filename} frame {i}\"):\n",
        "                sum_image += frame.astype(np.float32) / max(1, number_of_frames or 1)\n",
        "\n",
        "            # Interpolate to match trained models effective resolution  (OOM-prone)\n",
        "            with catch_oom(\"interpolating frame\", f\"{filename} frame {i}\"):\n",
        "                if interpolate_based_on_imaging_parameters:\n",
        "                    frame_i = interpolate_frames(\n",
        "                        frame,\n",
        "                        model_pixel_size, pixel_size,\n",
        "                        model_wavelength, wavelength,\n",
        "                        model_NA, numerical_aperture\n",
        "                    )[0]\n",
        "                else:\n",
        "                    frame_i = frame\n",
        "\n",
        "            if 'frame_i' not in locals():\n",
        "                # interpolation OOM'd; skip this frame\n",
        "                continue\n",
        "\n",
        "            M, N = frame_i.shape\n",
        "\n",
        "            # Background subtraction + standardization (dtype-safe)\n",
        "            fproc = np.asarray(frame_i, dtype=np.float32)   # <-- ensure float32\n",
        "            p35   = np.percentile(fproc, 35)                # float64 scalar is fine to subtract from float32 array\n",
        "            fproc = fproc - p35\n",
        "            fproc = fproc - fproc.min()\n",
        "\n",
        "            # use float64 accumulators for mean/std for stability, then cast back stays float32\n",
        "            fmean = fproc.mean(dtype=np.float64)\n",
        "            fstd  = fproc.std(dtype=np.float64) + 1e-6\n",
        "            fproc = (fproc - fmean) / fstd\n",
        "\n",
        "            # Split into patches (may allocate moderately)\n",
        "            with catch_oom(\"splitting into patches\", f\"{filename} frame {i}\"):\n",
        "                patches = split_image_to_patches(fproc, num_patches, overlap)\n",
        "            if 'patches' not in locals():\n",
        "                continue\n",
        "\n",
        "            offset = fproc.mean()\n",
        "\n",
        "            # Per-patch difficulty selection\n",
        "            for m in range(num_patches):\n",
        "                for n in range(num_patches):\n",
        "                    down  = overlap if m == 0 else 0\n",
        "                    up    = (M // num_patches) - overlap if m == num_patches - 1 else (M // num_patches)\n",
        "                    left  = overlap if n == 0 else 0\n",
        "                    right = (N // num_patches) - overlap if n == num_patches - 1 else (N // num_patches)\n",
        "\n",
        "                    with catch_oom(\"extracting features\", f\"{filename} frame {i} patch ({m},{n})\"):\n",
        "                        outputs = extract_features_frame(\n",
        "                            patches[m*num_patches+n][down:up, left:right],\n",
        "                            pixel_size,\n",
        "                            psf_sigma_pixels,\n",
        "                            offset=offset,\n",
        "                            verbose=verbose\n",
        "                        )\n",
        "                    if 'outputs' not in locals():\n",
        "                        continue\n",
        "\n",
        "                    curr_mean_noise, curr_std_noise, signal_amp, curr_emitter_density = outputs\n",
        "\n",
        "                    if (signal_amp == 0 or curr_mean_noise == 0):\n",
        "                        continue\n",
        "                    if any(np.isnan(v) for v in (signal_amp, curr_mean_noise, curr_std_noise, curr_emitter_density)):\n",
        "                        continue\n",
        "\n",
        "                    difficulty_choice = ChooseNetByDifficulty_2025(curr_emitter_density, signal_amp/curr_mean_noise)\n",
        "                    patches_list[difficulty_choice].append(patches[m*num_patches+n])\n",
        "                    patch_indices_list[difficulty_choice].append(m*num_patches+n)\n",
        "                    frame_numbers[difficulty_choice].append(i)\n",
        "\n",
        "        # --------------------------------------------------------------------------\n",
        "        # The rest of your pipeline below stays the SAME (with small guards)\n",
        "        # --------------------------------------------------------------------------\n",
        "        selected_model_hist = np.array([len(p) for p in patches_list], dtype=float)\n",
        "        if HEADLESS_PREVIEW:\n",
        "            with catch_oom(\"plotting model histogram\", filename):\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                plt.bar(np.arange(len(model_names)), selected_model_hist, width=0.8)\n",
        "                plt.xticks(np.arange(len(model_names)), model_names)\n",
        "                plt.xlabel('selected model')\n",
        "                plt.ylabel('number of patches to be analyzed by this model')\n",
        "                plt.show()\n",
        "\n",
        "        # If nothing was collected, skip reconstruction gracefully\n",
        "        if sum(len(p) for p in patches_list) == 0:\n",
        "            print(f\"  No usable patches for {filename}; skipping reconstruction.\")\n",
        "            continue\n",
        "\n",
        "        # M,N from last frame_i; safe because we had at least one patch\n",
        "        patchwise_recon = np.zeros([M * upsampling_factor, N * upsampling_factor], dtype=np.float32)\n",
        "        frame_number_list, x_nm_list, y_nm_list, confidence_au_list = [], [], [], []\n",
        "\n",
        "        log('Analyzing patches for each model')\n",
        "        for model_num, model_name in enumerate(model_names):\n",
        "            model_dir = os.path.join(prediction_model_path, model_name)\n",
        "            if os.path.exists(model_dir):\n",
        "                log(f\"The {os.path.basename(model_dir)} model will be used.\")\n",
        "            else:\n",
        "                log('!! WARNING: The chosen model does not exist !!')\n",
        "                log('Please make sure you provide a valid model path before proceeding further.')\n",
        "\n",
        "            if use_local_average:\n",
        "                log('Using local averaging')\n",
        "\n",
        "            if not os.path.exists(Result_folder):\n",
        "                log('Result folder was created.')\n",
        "                os.makedirs(Result_folder, exist_ok=True)\n",
        "\n",
        "            if patches_list[model_num]:\n",
        "                log(\"Reconstructing in chunks\")\n",
        "                total_chunks = (len(patches_list[model_num]) // chunk_size) + 1\n",
        "                for chunk_num in tqdm(range(total_chunks)):\n",
        "                    chunk_start = chunk_num * chunk_size\n",
        "                    chunk_end = min((chunk_num + 1) * chunk_size, len(patches_list[model_num]))\n",
        "\n",
        "                    if chunk_start >= chunk_end:\n",
        "                        continue\n",
        "\n",
        "                    with catch_oom(\"reconstructing chunk\",\n",
        "                                   detail=f\"{model_name} [{chunk_start}:{chunk_end}] of {len(patches_list[model_num])}\"):\n",
        "                        pw_recon, loc_list = reconstruct_patches_2025(\n",
        "                            patches_list[model_num][chunk_start:chunk_end],\n",
        "                            patch_indices_list[model_num][chunk_start:chunk_end],\n",
        "                            frame_numbers[model_num][chunk_start:chunk_end],\n",
        "                            os.path.join(prediction_model_path, model_names[model_num], 'best_weights.h5'),\n",
        "                            num_patches,\n",
        "                            overlap * upsampling_factor,\n",
        "                            number_of_frames,\n",
        "                            threshold,\n",
        "                            neighborhood_size=neighborhood_size,\n",
        "                            use_local_avg=use_local_average,\n",
        "                            upsampling_factor=upsampling_factor,\n",
        "                            pixel_size=pixel_size,\n",
        "                            batch_size=batch_size\n",
        "                        )\n",
        "\n",
        "                        # If OOM occurred inside, pw_recon may be undefined\n",
        "                        if 'pw_recon' in locals() and pw_recon is not None:\n",
        "                            frame_number_list += loc_list[0]\n",
        "                            x_nm_list += loc_list[1]\n",
        "                            y_nm_list += loc_list[2]\n",
        "                            confidence_au_list += loc_list[3]\n",
        "\n",
        "                            patchwise_recon[:M//num_patches*upsampling_factor*num_patches,\n",
        "                                            :N//num_patches*upsampling_factor*num_patches] += pw_recon\n",
        "\n",
        "        ext = '_avg' if use_local_average else '_max'\n",
        "        base = os.path.splitext(filename)[0]\n",
        "\n",
        "        # Save outputs (guarded)\n",
        "        with catch_oom(\"saving outputs\", base):\n",
        "            with open(os.path.join(Result_folder, f'Localizations_{base}{ext}.csv'), \"w\", newline='') as file:\n",
        "                writer = csv.writer(file)\n",
        "                writer.writerow(['frame', 'x [nm]', 'y [nm]', 'confidence [a.u]'])\n",
        "                sort_ind = np.argsort(frame_number_list)\n",
        "                locs = list(zip(list(np.array(frame_number_list)[sort_ind]),\n",
        "                                list(np.array(x_nm_list)[sort_ind]),\n",
        "                                list(np.array(y_nm_list)[sort_ind]),\n",
        "                                list(np.array(confidence_au_list)[sort_ind])))\n",
        "                writer.writerows(locs)\n",
        "\n",
        "            pw_recon_tif = np.copy(patchwise_recon)\n",
        "            cap = np.percentile(pw_recon_tif, 99.5)\n",
        "            pw_recon_tif[pw_recon_tif > cap] = cap\n",
        "            saveAsTIF(Result_folder, f'Predicted_patchwise_{base}', pw_recon_tif, pixel_size/upsampling_factor)\n",
        "\n",
        "        log('--------------------------------------------------------------------')\n",
        "        log('---------------------------- Previews ------------------------------')\n",
        "        log('--------------------------------------------------------------------')\n",
        "        if HEADLESS_PREVIEW:\n",
        "            with catch_oom(\"plotting previews\", filename):\n",
        "                fig, axes = plt.subplots(1, 3, figsize=(20,16))\n",
        "                axes[0].axis('off'); axes[0].imshow(sum_image); axes[0].set_title('Original', fontsize=15)\n",
        "                axes[1].axis('off'); axes[1].imshow(patchwise_recon); axes[1].set_title('Prediction', fontsize=15)\n",
        "                axes[2].axis('off'); axes[2].imshow(np.clip(patchwise_recon,\n",
        "                                                            np.percentile(patchwise_recon, 1),\n",
        "                                                            np.percentile(patchwise_recon, 99)))\n",
        "                axes[2].set_title('Normalized Prediction', fontsize=15)\n",
        "                plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Drift Correction\n",
        "\n",
        "## **6.2 Drift correction**\n",
        "# @markdown ##Data parameters\n",
        "Loc_file_path = \"\" #@param {type:\"string\"}\n",
        "# @markdown Provide information about original data. Get the info automatically from the raw data?\n",
        "Get_info_from_file = False #@param {type:\"boolean\"}\n",
        "# Loc_file_path = \"/content/gdrive/My Drive/Colab notebooks testing/DeepSTORM/Glia data from CL/Results from prediction/20200615-M6 with CoM localizations/Localizations_glia_actin_2D - 1-500fr_avg.csv\" #@param {type:\"string\"}\n",
        "original_image_path = \"\" #@param {type:\"string\"}\n",
        "# @markdown Otherwise, please provide image width, height (in pixels) and pixel size (in nm)\n",
        "image_width = 40 #@param {type:\"integer\"}\n",
        "image_height = 40 #@param {type:\"integer\"}\n",
        "\n",
        "# @markdown ##Drift correction parameters\n",
        "visualization_pixel_size = 10 #@param {type:\"number\"}\n",
        "number_of_bins = 10 #@param {type:\"integer\"}\n",
        "polynomial_fit_degree = 4 #@param {type:\"integer\"}\n",
        "\n",
        "# @markdown ##Saving parameters\n",
        "save_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# Read the localizations in\n",
        "LocData = pd.read_csv(Loc_file_path)\n",
        "\n",
        "# Calculate a few variables\n",
        "Mhr = int(math.ceil(image_height*pixel_size/visualization_pixel_size))\n",
        "Nhr = int(math.ceil(image_width*pixel_size/visualization_pixel_size))\n",
        "nFrames = LocData['frame'].max() + 1\n",
        "\n",
        "x_max = max(LocData['x [nm]'])\n",
        "y_max = max(LocData['y [nm]'])\n",
        "image_size = (Mhr, Nhr)\n",
        "n_locs = len(LocData.index)\n",
        "\n",
        "print('Image size: '+str(image_size))\n",
        "print('Number of frames in data: '+str(nFrames))\n",
        "print('Number of localizations in data: '+str(n_locs))\n",
        "\n",
        "blocksize = math.ceil(nFrames/number_of_bins)\n",
        "print('Number of frames per block: '+str(blocksize))\n",
        "\n",
        "blockDataFrame = LocData[(LocData['frame'] < blocksize)].copy()\n",
        "xc_array = blockDataFrame['x [nm]'].to_numpy(dtype=np.float32)\n",
        "yc_array = blockDataFrame['y [nm]'].to_numpy(dtype=np.float32)\n",
        "\n",
        "# Preparing the Reference image\n",
        "photon_array = np.ones(yc_array.shape[0])\n",
        "sigma_array = np.ones(yc_array.shape[0])\n",
        "ImagesRef = FromLoc2Image_SimpleHistogram(xc_array, yc_array, image_size=image_size, pixel_size=visualization_pixel_size)\n",
        "ImagesRef = np.flip(np.flip(ImagesRef, axis=0), axis=1)\n",
        "\n",
        "xDrift = np.zeros(number_of_bins)\n",
        "yDrift = np.zeros(number_of_bins)\n",
        "\n",
        "filename_no_extension = os.path.splitext(os.path.basename(Loc_file_path))[0]\n",
        "\n",
        "with open(os.path.join(save_path, filename_no_extension+\"_DriftCorrectionData.csv\"), \"w\", newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "\n",
        "      # Write the header in the csv file\n",
        "      writer.writerow([\"Block #\", \"x-drift [nm]\",\"y-drift [nm]\"])\n",
        "\n",
        "      for b in tqdm(range(number_of_bins)):\n",
        "            blockDataFrame = LocData[(LocData['frame'] >= (b*blocksize)) & (LocData['frame'] < ((b+1)*blocksize))].copy()\n",
        "            xc_array = blockDataFrame['x [nm]'].to_numpy(dtype=np.float32)\n",
        "            yc_array = blockDataFrame['y [nm]'].to_numpy(dtype=np.float32)\n",
        "\n",
        "            photon_array = np.ones(yc_array.shape[0])\n",
        "            sigma_array = np.ones(yc_array.shape[0])\n",
        "            ImageBlock = FromLoc2Image_SimpleHistogram(xc_array, yc_array, image_size=image_size, pixel_size=visualization_pixel_size)\n",
        "\n",
        "            XC = fftconvolve(gaussian_filter(ImagesRef, 2), gaussian_filter(ImageBlock, 2), mode='same')\n",
        "            yDrift[b], xDrift[b] = estimate_drift_com_nm(ImagesRef, ImageBlock, visualization_pixel_size, sigma=1.0, patch_radius=np.min([Mhr, Nhr])//2)\n",
        "\n",
        "            # saveAsTIF(save_path, 'ImageBlock'+str(b), ImageBlock, visualization_pixel_size)\n",
        "            # saveAsTIF(save_path, 'XCBlock'+str(b), XC, visualization_pixel_size)\n",
        "            writer.writerow([str(b), str((xDrift[b]-xDrift[0])), str((yDrift[b]-yDrift[0]))])\n",
        "\n",
        "print('--------------------------------------------------------------------')\n",
        "\n",
        "print('Fitting drift data...')\n",
        "bin_number = np.arange(number_of_bins)*blocksize + blocksize/2\n",
        "xDrift = (xDrift-xDrift[0])\n",
        "yDrift = (yDrift-yDrift[0])\n",
        "\n",
        "xDriftCoeff = np.polyfit(bin_number, xDrift, polynomial_fit_degree)\n",
        "yDriftCoeff = np.polyfit(bin_number, yDrift, polynomial_fit_degree)\n",
        "\n",
        "xDriftFit = np.poly1d(xDriftCoeff)\n",
        "yDriftFit = np.poly1d(yDriftCoeff)\n",
        "bins = np.arange(nFrames)\n",
        "xDriftInterpolated = xDriftFit(bins)\n",
        "yDriftInterpolated = yDriftFit(bins)\n",
        "\n",
        "# ------------------ Displaying the image results ------------------\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(bin_number,xDrift, 'r+', label='x-drift')\n",
        "plt.plot(bin_number,yDrift, 'b+', label='y-drift')\n",
        "plt.plot(bins,xDriftInterpolated, 'r-', label='y-drift (fit)')\n",
        "plt.plot(bins,yDriftInterpolated, 'b-', label='y-drift (fit)')\n",
        "plt.title('Cross-correlation estimated drift')\n",
        "plt.ylabel('Drift [nm]')\n",
        "plt.xlabel('Bin number/ Time point')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ------------------ Actual drift correction -------------------\n",
        "\n",
        "print('Correcting localization data...')\n",
        "xc_array = LocData['x [nm]'].to_numpy(dtype=np.float32)\n",
        "yc_array = LocData['y [nm]'].to_numpy(dtype=np.float32)\n",
        "frames = LocData['frame'].to_numpy(dtype=np.int32)\n",
        "\n",
        "xc_array_Corr, yc_array_Corr = correctDriftLocalization(xc_array, yc_array, frames, xDriftInterpolated, yDriftInterpolated)\n",
        "ImageRaw = FromLoc2Image_SimpleHistogram(xc_array, yc_array, image_size=image_size, pixel_size=visualization_pixel_size)\n",
        "ImageCorr = FromLoc2Image_SimpleHistogram(xc_array_Corr, yc_array_Corr, image_size=image_size, pixel_size=visualization_pixel_size)\n",
        "\n",
        "# ------------------ Displaying the imge results ------------------\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 7.5), sharex=True, sharey=True)\n",
        "# Raw\n",
        "axs[0].axis('off')\n",
        "axs[0].imshow(np.log(ImageRaw + 1e-3), cmap='gray')\n",
        "axs[0].set_title('Raw', fontsize=15)\n",
        "# Corrected\n",
        "axs[1].axis('off')\n",
        "axs[1].imshow(np.log(ImageCorr + 1e-3), cmap='gray')\n",
        "axs[1].set_title('Corrected', fontsize=15)\n",
        "plt.show()\n",
        "\n",
        "# ------------------ Table with info -------------------\n",
        "driftCorrectedLocData = pd.DataFrame()\n",
        "driftCorrectedLocData['frame'] = frames\n",
        "driftCorrectedLocData['x [nm]'] = xc_array_Corr\n",
        "driftCorrectedLocData['y [nm]'] = yc_array_Corr\n",
        "driftCorrectedLocData['confidence [a.u]'] = LocData['confidence [a.u]']\n",
        "\n",
        "driftCorrectedLocData.to_csv(os.path.join(save_path, filename_no_extension+'_DriftCorrected.csv'))\n",
        "print('-------------------------------')\n",
        "print('Corrected localizations saved.')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TuOgWxsTV2LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BvykD0YIk89"
      },
      "source": [
        "# **Version log**\n",
        "---\n",
        "<font size = 4>**v1.0**: Initial implementation\n",
        "\n",
        "<font size = 4>**v1.1**: Improving resource management. Automatic model loading.\n",
        "\n",
        "<font size = 4>**v1.2**: ND2 compatability. Further improvement of memory management\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgN-NooKk3nV"
      },
      "source": [
        "\n",
        "#**Thank you for using AutoDS!**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}